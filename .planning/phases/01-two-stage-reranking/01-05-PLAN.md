---
phase: 01-two-stage-reranking
plan: 05
type: execute
wave: 3
depends_on: ["01-03", "01-04"]
files_modified:
  - agent-brain-server/agent_brain_server/services/query_service.py
  - agent-brain-server/agent_brain_server/models/query.py
autonomous: true

must_haves:
  truths:
    - "Reranking is applied after RRF fusion when ENABLE_RERANKING=true"
    - "Stage 1 retrieves top_k * multiplier candidates (capped at 100)"
    - "Reranking failures fall back to stage 1 results gracefully"
    - "QueryResult includes rerank_score and original_rank fields"
  artifacts:
    - path: "agent-brain-server/agent_brain_server/services/query_service.py"
      provides: "_rerank_results() method and integration"
      contains: "_rerank_results"
    - path: "agent-brain-server/agent_brain_server/models/query.py"
      provides: "rerank_score and original_rank fields"
      contains: "rerank_score"
  key_links:
    - from: "services/query_service.py"
      to: "providers/factory.py"
      via: "ProviderRegistry.get_reranker_provider"
      pattern: "ProviderRegistry.get_reranker_provider"
    - from: "services/query_service.py"
      to: "config/settings.py"
      via: "settings.ENABLE_RERANKING check"
      pattern: "settings.ENABLE_RERANKING"
---

<objective>
Integrate reranking into the query service as optional two-stage retrieval.

Purpose: Enable users to get more accurate search results when reranking is enabled.
Output: Working two-stage retrieval with graceful fallback on failure.
</objective>

<execution_context>
@/Users/richardhightower/.claude/get-shit-done/workflows/execute-plan.md
@/Users/richardhightower/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-two-stage-reranking/01-RESEARCH.md
@.planning/phases/01-two-stage-reranking/01-03-SUMMARY.md
@.planning/phases/01-two-stage-reranking/01-04-SUMMARY.md
@agent-brain-server/agent_brain_server/services/query_service.py
@agent-brain-server/agent_brain_server/models/query.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add rerank_score and original_rank to QueryResult</name>
  <files>agent-brain-server/agent_brain_server/models/query.py</files>
  <action>
Add new fields to the QueryResult model after the existing graph_score field:

```python
class QueryResult(BaseModel):
    """Single query result with source and score."""

    text: str = Field(..., description="The chunk text content")
    source: str = Field(..., description="Source file path")
    score: float = Field(..., description="Primary score (rank or similarity)")
    vector_score: float | None = Field(
        default=None, description="Score from vector search"
    )
    bm25_score: float | None = Field(default=None, description="Score from BM25 search")
    chunk_id: str = Field(..., description="Unique chunk identifier")

    # Content type information
    source_type: str = Field(
        default="doc", description="Type of content: 'doc', 'code', or 'test'"
    )
    language: str | None = Field(
        default=None, description="Programming language for code files"
    )

    # GraphRAG fields (Feature 113)
    graph_score: float | None = Field(
        default=None, description="Score from graph-based retrieval"
    )
    related_entities: list[str] | None = Field(
        default=None, description="Related entities from knowledge graph"
    )
    relationship_path: list[str] | None = Field(
        default=None, description="Relationship paths in the graph"
    )

    # Reranking fields (Feature 123)
    rerank_score: float | None = Field(
        default=None, description="Score from reranking stage (if enabled)"
    )
    original_rank: int | None = Field(
        default=None, description="Position before reranking (1-indexed)"
    )

    # Additional metadata
    metadata: dict[str, Any] = Field(
        default_factory=dict, description="Additional metadata"
    )
```

Also update the JSON schema example to show the new fields (optional).
  </action>
  <verify>Run `cd agent-brain-server && poetry run python -c "from agent_brain_server.models.query import QueryResult; r = QueryResult(text='test', source='test.py', score=0.9, chunk_id='c1'); print(r.rerank_score, r.original_rank)"` to verify the new fields are accessible and default to None.</verify>
  <done>QueryResult has rerank_score and original_rank fields with None defaults.</done>
</task>

<task type="auto">
  <name>Task 2: Add _rerank_results method to QueryService</name>
  <files>agent-brain-server/agent_brain_server/services/query_service.py</files>
  <action>
Add imports at the top of the file:

```python
from agent_brain_server.config.provider_config import load_provider_settings
from agent_brain_server.providers.factory import ProviderRegistry
# Note: reranker package import triggers provider registration
import agent_brain_server.providers.reranker  # noqa: F401
```

Add the _rerank_results method to the QueryService class:

```python
async def _rerank_results(
    self,
    results: list[QueryResult],
    query: str,
    top_k: int,
) -> list[QueryResult]:
    """Apply two-stage reranking to search results.

    Args:
        results: Stage 1 results (more than needed).
        query: Original search query.
        top_k: Final number of results to return.

    Returns:
        Reranked results with rerank_score and original_rank populated.
        Falls back to truncated stage 1 results on any failure.
    """
    if not results:
        return results

    try:
        # Get reranker provider from config
        provider_settings = load_provider_settings()
        reranker = ProviderRegistry.get_reranker_provider(
            provider_settings.reranker
        )

        # Check if reranker is available
        if not reranker.is_available():
            logger.warning(
                f"Reranker {reranker.provider_name} not available, "
                "using stage 1 results"
            )
            return results[:top_k]

        # Extract document texts for reranking
        documents = [r.text for r in results]

        # Perform reranking
        import time
        start = time.time()
        reranked = await reranker.rerank(query, documents, top_k=top_k)
        rerank_time_ms = (time.time() - start) * 1000

        logger.info(
            f"Reranked {len(documents)} candidates to top {top_k} "
            f"in {rerank_time_ms:.1f}ms using {reranker.provider_name}"
        )

        # Build reranked results with scores
        reranked_results: list[QueryResult] = []
        for new_rank, (original_idx, rerank_score) in enumerate(reranked):
            result = results[original_idx]
            # Update result with reranking info
            result.rerank_score = rerank_score
            result.original_rank = original_idx + 1  # 1-indexed
            # Update primary score to rerank score
            result.score = rerank_score
            reranked_results.append(result)

        return reranked_results

    except Exception as e:
        # Graceful fallback: return stage 1 results
        logger.warning(
            f"Reranking failed, using stage 1 results: {e}"
        )
        return results[:top_k]
```
  </action>
  <verify>Run `cd agent-brain-server && poetry run python -c "from agent_brain_server.services.query_service import QueryService; qs = QueryService(); print(hasattr(qs, '_rerank_results'))"` to verify the method exists.</verify>
  <done>_rerank_results method exists with graceful fallback on failure.</done>
</task>

<task type="auto">
  <name>Task 3: Integrate reranking into execute_query flow</name>
  <files>agent-brain-server/agent_brain_server/services/query_service.py</files>
  <action>
Modify the execute_query method to apply reranking when enabled. Update the method to:

1. Determine stage 1 top_k based on settings:
```python
async def execute_query(self, request: QueryRequest) -> QueryResponse:
    """Execute a search query with optional reranking."""
    if not self.is_ready():
        raise RuntimeError(
            "Query service not ready. Please wait for indexing to complete."
        )

    start_time = time.time()

    # Calculate stage 1 top_k if reranking is enabled
    stage1_top_k = request.top_k
    if settings.ENABLE_RERANKING:
        # Retrieve more candidates for reranking
        stage1_top_k = min(
            request.top_k * settings.RERANKER_TOP_K_MULTIPLIER,
            settings.RERANKER_MAX_CANDIDATES,
        )
        logger.debug(
            f"Reranking enabled: retrieving {stage1_top_k} candidates for stage 1"
        )

    # Create modified request for stage 1 retrieval
    stage1_request = QueryRequest(
        query=request.query,
        top_k=stage1_top_k,
        similarity_threshold=request.similarity_threshold,
        mode=request.mode,
        alpha=request.alpha,
        source_types=request.source_types,
        languages=request.languages,
        file_paths=request.file_paths,
    )

    # Execute retrieval based on mode
    if request.mode == QueryMode.BM25:
        results = await self._execute_bm25_query(stage1_request)
    elif request.mode == QueryMode.VECTOR:
        results = await self._execute_vector_query(stage1_request)
    elif request.mode == QueryMode.GRAPH:
        results = await self._execute_graph_query(stage1_request)
    elif request.mode == QueryMode.MULTI:
        results = await self._execute_multi_query(stage1_request)
    else:  # HYBRID
        results = await self._execute_hybrid_query(stage1_request)

    # Apply reranking if enabled
    if settings.ENABLE_RERANKING and len(results) > request.top_k:
        results = await self._rerank_results(results, request.query, request.top_k)
    else:
        # Truncate to requested top_k
        results = results[:request.top_k]

    # Apply content filters if specified
    if any([request.source_types, request.languages, request.file_paths]):
        results = self._filter_results(results, request)

    query_time_ms = (time.time() - start_time) * 1000

    logger.debug(
        f"Query ({request.mode}) '{request.query[:50]}...' returned "
        f"{len(results)} results in {query_time_ms:.2f}ms"
        f"{' (reranked)' if settings.ENABLE_RERANKING else ''}"
    )

    return QueryResponse(
        results=results,
        query_time_ms=query_time_ms,
        total_results=len(results),
    )
```
  </action>
  <verify>Run `cd agent-brain-server && poetry run python -c "from agent_brain_server.services.query_service import QueryService; from agent_brain_server.models import QueryRequest; import asyncio; qs = QueryService(); print('Query service loads with reranking integration')"` to verify the integration doesn't break existing functionality.</verify>
  <done>execute_query integrates reranking when ENABLE_RERANKING=true with correct stage 1 retrieval multiplier.</done>
</task>

</tasks>

<verification>
1. QueryResult has rerank_score and original_rank fields
2. _rerank_results method wraps reranker call with try/except
3. execute_query retrieves extra candidates when reranking enabled
4. Graceful fallback returns stage 1 results on any failure
5. Reranking is skipped when results <= top_k
</verification>

<success_criteria>
- With ENABLE_RERANKING=false: queries work exactly as before
- With ENABLE_RERANKING=true: stage 1 retrieves 10x candidates, stage 2 reranks
- Reranker failure logs warning and returns stage 1 results
- Results include rerank_score when reranking was applied
- Query time includes reranking latency
</success_criteria>

<output>
After completion, create `.planning/phases/01-two-stage-reranking/01-05-SUMMARY.md`
</output>
