---
phase: 01-two-stage-reranking
plan: 03
type: execute
wave: 2
depends_on: ["01-01", "01-02"]
files_modified:
  - agent-brain-server/agent_brain_server/providers/reranker/sentence_transformers.py
  - agent-brain-server/agent_brain_server/providers/reranker/__init__.py
  - agent-brain-server/pyproject.toml
autonomous: true

must_haves:
  truths:
    - "SentenceTransformerRerankerProvider uses CrossEncoder.rank() method"
    - "Reranking runs in thread pool to avoid blocking async loop"
    - "Provider is registered with ProviderRegistry on import"
  artifacts:
    - path: "agent-brain-server/agent_brain_server/providers/reranker/sentence_transformers.py"
      provides: "SentenceTransformerRerankerProvider implementation"
      contains: "class SentenceTransformerRerankerProvider"
    - path: "agent-brain-server/pyproject.toml"
      provides: "sentence-transformers dependency"
      contains: "sentence-transformers"
  key_links:
    - from: "providers/reranker/sentence_transformers.py"
      to: "sentence_transformers.CrossEncoder"
      via: "import"
      pattern: "from sentence_transformers import CrossEncoder"
---

<objective>
Implement SentenceTransformerRerankerProvider using the sentence-transformers CrossEncoder.

Purpose: Provide the primary reranking implementation using industry-standard cross-encoder models.
Output: Working sentence-transformers reranker provider with proper async handling.
</objective>

<execution_context>
@/Users/richardhightower/.claude/get-shit-done/workflows/execute-plan.md
@/Users/richardhightower/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-two-stage-reranking/01-RESEARCH.md
@.planning/phases/01-two-stage-reranking/01-01-SUMMARY.md
@.planning/phases/01-two-stage-reranking/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add sentence-transformers dependency</name>
  <files>agent-brain-server/pyproject.toml</files>
  <action>
Add sentence-transformers to the dependencies in pyproject.toml:

```toml
[tool.poetry.dependencies]
# ... existing dependencies ...
sentence-transformers = "^3.4.0"
```

Then run `cd agent-brain-server && poetry lock --no-update && poetry install` to update the lock file and install.

Note: sentence-transformers pulls in torch which is large. This is expected.
  </action>
  <verify>Run `cd agent-brain-server && poetry run python -c "from sentence_transformers import CrossEncoder; print('sentence-transformers installed')"` to verify the package is available.</verify>
  <done>sentence-transformers is listed in pyproject.toml and installed.</done>
</task>

<task type="auto">
  <name>Task 2: Implement SentenceTransformerRerankerProvider</name>
  <files>agent-brain-server/agent_brain_server/providers/reranker/sentence_transformers.py</files>
  <action>
Create the sentence-transformers reranker implementation:

```python
"""SentenceTransformer CrossEncoder reranking provider."""

import asyncio
import logging
from typing import TYPE_CHECKING

from sentence_transformers import CrossEncoder

from agent_brain_server.providers.factory import ProviderRegistry
from agent_brain_server.providers.reranker.base import BaseRerankerProvider

if TYPE_CHECKING:
    from agent_brain_server.config.provider_config import RerankerConfig

logger = logging.getLogger(__name__)


class SentenceTransformerRerankerProvider(BaseRerankerProvider):
    """Reranker using sentence-transformers CrossEncoder.

    Uses pre-trained cross-encoder models for accurate document reranking.
    The CrossEncoder scores query-document pairs directly, providing
    more accurate relevance scores than bi-encoder similarity.

    Default model: cross-encoder/ms-marco-MiniLM-L-6-v2 (fast, good accuracy)
    Alternative: cross-encoder/ms-marco-MiniLM-L-12-v2 (slower, better accuracy)
    """

    def __init__(self, config: "RerankerConfig") -> None:
        """Initialize the CrossEncoder reranker.

        Args:
            config: Reranker configuration.
        """
        super().__init__(config)
        self._cross_encoder: CrossEncoder | None = None
        self._model_loaded = False

    def _ensure_model_loaded(self) -> CrossEncoder:
        """Lazy-load the CrossEncoder model.

        Returns:
            Loaded CrossEncoder instance.
        """
        if self._cross_encoder is None:
            logger.info(f"Loading CrossEncoder model: {self._model}")
            self._cross_encoder = CrossEncoder(self._model)
            self._model_loaded = True
            logger.info(f"CrossEncoder model loaded: {self._model}")
        return self._cross_encoder

    async def rerank(
        self,
        query: str,
        documents: list[str],
        top_k: int = 10,
    ) -> list[tuple[int, float]]:
        """Rerank documents using CrossEncoder.

        Uses CrossEncoder.rank() for efficient batch scoring and sorting.
        Runs in thread pool to avoid blocking the async event loop.

        Args:
            query: The search query.
            documents: List of document texts to rerank.
            top_k: Number of top results to return.

        Returns:
            List of (original_index, score) tuples, sorted by score descending.
        """
        if not documents:
            return []

        # Limit top_k to document count
        effective_top_k = min(top_k, len(documents))

        # Run CrossEncoder in thread pool (CPU-bound operation)
        results = await asyncio.to_thread(
            self._rerank_sync,
            query,
            documents,
            effective_top_k,
        )

        logger.debug(
            f"Reranked {len(documents)} documents, returning top {effective_top_k}"
        )

        return results

    def _rerank_sync(
        self,
        query: str,
        documents: list[str],
        top_k: int,
    ) -> list[tuple[int, float]]:
        """Synchronous reranking implementation.

        Args:
            query: The search query.
            documents: List of document texts.
            top_k: Number of results to return.

        Returns:
            List of (corpus_id, score) tuples.
        """
        model = self._ensure_model_loaded()

        # CrossEncoder.rank() returns sorted results with corpus_id and score
        # return_documents=False for efficiency (we don't need the text back)
        ranked = model.rank(
            query,
            documents,
            top_k=top_k,
            return_documents=False,
        )

        # Convert to (index, score) tuples
        return [(r["corpus_id"], float(r["score"])) for r in ranked]

    @property
    def provider_name(self) -> str:
        """Human-readable provider name."""
        return "SentenceTransformers"

    def is_available(self) -> bool:
        """Check if CrossEncoder can be loaded.

        Returns:
            True if model can be loaded, False otherwise.
        """
        try:
            self._ensure_model_loaded()
            return True
        except Exception as e:
            logger.warning(f"CrossEncoder not available: {e}")
            return False


# Register provider on import
ProviderRegistry.register_reranker_provider(
    "sentence-transformers",
    SentenceTransformerRerankerProvider,
)
```
  </action>
  <verify>Run `cd agent-brain-server && poetry run python -c "from agent_brain_server.providers.reranker.sentence_transformers import SentenceTransformerRerankerProvider; from agent_brain_server.providers.factory import ProviderRegistry; print(ProviderRegistry.get_available_reranker_providers())"` to verify the provider is registered.</verify>
  <done>SentenceTransformerRerankerProvider is implemented and registered with factory.</done>
</task>

<task type="auto">
  <name>Task 3: Update reranker package exports</name>
  <files>agent-brain-server/agent_brain_server/providers/reranker/__init__.py</files>
  <action>
Update the package __init__.py to export the new provider:

```python
"""Reranking providers package."""

from agent_brain_server.providers.reranker.base import (
    BaseRerankerProvider,
    RerankerProvider,
)
from agent_brain_server.providers.reranker.sentence_transformers import (
    SentenceTransformerRerankerProvider,
)

__all__ = [
    "BaseRerankerProvider",
    "RerankerProvider",
    "SentenceTransformerRerankerProvider",
]
```

The import of sentence_transformers module triggers provider registration.
  </action>
  <verify>Run `cd agent-brain-server && poetry run python -c "from agent_brain_server.providers.reranker import SentenceTransformerRerankerProvider; print('Export works')"` to verify the export is available.</verify>
  <done>SentenceTransformerRerankerProvider is exported from reranker package.</done>
</task>

</tasks>

<verification>
1. sentence-transformers is installed and importable
2. SentenceTransformerRerankerProvider uses CrossEncoder.rank() method
3. Provider runs inference in thread pool (asyncio.to_thread)
4. Provider is registered with ProviderRegistry on import
5. Lazy model loading prevents startup overhead
</verification>

<success_criteria>
- poetry install succeeds with sentence-transformers
- CrossEncoder model can be loaded (first call may be slow due to download)
- rerank() method returns correctly sorted (index, score) tuples
- Provider registration happens automatically on import
</success_criteria>

<output>
After completion, create `.planning/phases/01-two-stage-reranking/01-03-SUMMARY.md`
</output>
