---
phase: 10-live-postgres-e2e
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - agent-brain-server/tests/integration/test_postgres_e2e.py
autonomous: true

must_haves:
  truths:
    - "E2E test indexes real documents via API into live PostgreSQL and queries return relevant results"
    - "Cross-backend consistency test confirms 60%+ Jaccard overlap in top-5 hybrid results between ChromaDB and PostgreSQL"
    - "/health/postgres endpoint returns pool metrics (pool_size, checked_in, checked_out) when backend is postgres"
    - "All existing 654+ tests still pass after new test file is added"
  artifacts:
    - path: "agent-brain-server/tests/integration/test_postgres_e2e.py"
      provides: "Full-stack E2E tests with live PostgreSQL"
      contains: "class TestPostgresE2E"
  key_links:
    - from: "agent-brain-server/tests/integration/test_postgres_e2e.py"
      to: "agent_brain_server.api.main:app"
      via: "httpx ASGITransport with lifespan"
      pattern: "ASGITransport.*app"
    - from: "agent-brain-server/tests/integration/test_postgres_e2e.py"
      to: "PostgreSQL via DATABASE_URL"
      via: "AGENT_BRAIN_STORAGE_BACKEND=postgres env var triggers factory"
      pattern: "AGENT_BRAIN_STORAGE_BACKEND.*postgres"
---

<objective>
Create full-stack E2E integration tests that validate the complete PostgreSQL-backed workflow with a live database: configure backend, initialize app via lifespan, index real documents via API, query and verify results, check /health/postgres pool metrics, and confirm cross-backend hybrid search consistency.

Purpose: This is the FINAL validation phase for the v6.0 milestone. All PostgreSQL backend code was implemented in Phases 5-9, but only mock-based and contract tests exist. This plan proves the entire stack works end-to-end with a real database.

Output: `test_postgres_e2e.py` with 4-5 test functions covering all 5 success criteria.
</objective>

<execution_context>
@/Users/richardhightower/.claude/get-shit-done/workflows/execute-plan.md
@/Users/richardhightower/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-live-postgres-e2e/10-RESEARCH.md

# Existing test patterns to follow
@agent-brain-server/tests/contract/conftest.py
@agent-brain-server/tests/contract/test_hybrid_search_contract.py
@agent-brain-server/tests/load/test_postgres_pool.py
@agent-brain-server/tests/integration/test_backend_wiring.py

# Server entry point (lifespan to understand)
@agent-brain-server/agent_brain_server/api/main.py

# Health endpoint with /health/postgres
@agent-brain-server/agent_brain_server/api/routers/health.py

# Top-level conftest for singleton reset pattern
@agent-brain-server/tests/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create full-stack PostgreSQL E2E test file</name>
  <files>agent-brain-server/tests/integration/test_postgres_e2e.py</files>
  <action>
Create `agent-brain-server/tests/integration/test_postgres_e2e.py` with the following structure and tests. Follow the existing code style (Black 88, type hints on all functions, Google docstrings).

**Module-level setup:**
- `from __future__ import annotations`
- Import: `asyncio`, `os`, `pytest`, `httpx.ASGITransport`, `httpx.AsyncClient`, `Path`, `typing.Any`
- Import from codebase: `clear_settings_cache` from `agent_brain_server.config.provider_config`, `StorageBackendProtocol` from `agent_brain_server.storage.protocol`, `SearchResult` from `agent_brain_server.storage.protocol`
- `pytestmark` with `pytest.mark.postgres` and `pytest.mark.asyncio`
- Helper `_postgres_available()` checking for `asyncpg` importability AND `DATABASE_URL` env var (follow exact pattern from `tests/contract/conftest.py`)
- Module-level `skipif` decorator: `pytest.mark.skipif(not _postgres_available(), reason="PostgreSQL not available (requires DATABASE_URL and asyncpg)")`
- Apply the skipif to the entire module using a conditional skip at module top (not per-test, since all tests in this file need postgres)

**Fixtures:**
1. `postgres_app` fixture (scope="function"):
   - Set env vars: `AGENT_BRAIN_STORAGE_BACKEND=postgres`, ensure `DATABASE_URL` is set
   - Clear settings cache with `clear_settings_cache()`
   - Write a minimal provider config YAML to `tmp_path / "provider-config.yaml"` with `embedding:\n  params:\n    dimensions: 8\n` (8-dimensional embeddings for fast testing, matching contract test pattern)
   - Set `AGENT_BRAIN_CONFIG` env var to point to this config file
   - Import `app` from `agent_brain_server.api.main` AFTER setting env vars
   - Yield the app
   - In teardown: reset the storage backend via `app.state.storage_backend.reset()` if it exists, close it if it has `close()`, clear settings cache, reset factory singletons (import `reset_storage_backend_cache` from `agent_brain_server.storage.factory`)

2. `postgres_client` fixture (scope="function"):
   - Takes `postgres_app`
   - Create `ASGITransport(app=postgres_app)` and `AsyncClient(transport=..., base_url="http://test")`
   - Use `async with` to manage the lifespan context manager
   - Yield the client
   - IMPORTANT: The app lifespan must be triggered. Use `from asgi_lifespan import LifespanManager` if available, or manually invoke the lifespan. Since the project may not have `asgi-lifespan`, use a simpler approach: use `httpx.ASGITransport(app=app)` with `AsyncClient` -- but note that `httpx` does NOT trigger ASGI lifespan events by default.

   **Alternative approach (RECOMMENDED):** Instead of trying to trigger the full FastAPI lifespan via httpx (which is complex and fragile), test the PostgreSQL backend DIRECTLY at the service level, matching the existing contract test pattern. This avoids the complexity of lifespan management in tests while still validating the full flow (factory -> backend -> database).

   Revise the fixture approach:
   - `postgres_backend` fixture: Use the exact pattern from `tests/contract/conftest.py::_create_postgres_backend()`. Write provider config, set env var, create `PostgresConfig.from_database_url()`, create `PostgresBackend(config=config)`, call `await backend.initialize()`.
   - For service-level tests: Create `IndexingService(storage_backend=backend)` and `QueryService(storage_backend=backend)` -- this is exactly how `main.py` wires them in Phase 9.
   - For health endpoint tests: Test the `/health/postgres` endpoint by creating the app with mocked state that uses the real postgres backend.

**Test class `TestPostgresE2E`:**

1. `test_full_workflow_index_and_query(postgres_backend, tmp_path)`:
   - Create 3-5 markdown files in `tmp_path` with distinct content (Python programming, JavaScript development, Rust memory safety, etc.)
   - Create `IndexingService(storage_backend=postgres_backend)` and call `await indexing_service.index_folder(str(tmp_path))` to index the documents
   - Verify `await postgres_backend.get_count()` returns > 0 (documents were indexed)
   - Create `QueryService(storage_backend=postgres_backend)` and execute a query
   - For querying: call `await postgres_backend.vector_search(query_embedding=[...], top_k=5, similarity_threshold=0.0)` with a deterministic 8-dim embedding
   - Assert results are non-empty and scores are in [0.0, 1.0]
   - This validates Success Criteria #1

2. `test_health_postgres_pool_metrics(postgres_backend)`:
   - Call `await postgres_backend.connection_manager.get_pool_status()`
   - Assert the returned dict contains expected keys: `status`, `pool_size`, `checked_in`, `checked_out`, `overflow`, `total`
   - Assert `status == "active"`
   - Assert `pool_size >= 0` and `total >= pool_size`
   - This validates Success Criteria #4 (pool metrics accuracy -- the health endpoint just forwards these metrics)

3. `test_document_persistence_across_operations(postgres_backend, tmp_path)`:
   - Index documents
   - Call `await postgres_backend.get_count()` and store count
   - Call `await postgres_backend.vector_search(...)` to verify retrieval
   - Assert count matches expected number of indexed chunks
   - This validates data actually persists in PostgreSQL (not just in memory)

**Test class `TestCrossBackendConsistency`:**

4. `test_hybrid_search_similarity_chroma_vs_postgres(postgres_backend, tmp_path)`:
   - Create a ChromaDB backend using the pattern from `tests/contract/conftest.py::_create_chroma_backend(tmp_path / "chroma_dir")`
   - Seed BOTH backends with identical data using the HYBRID_DOCS pattern from `test_hybrid_search_contract.py` (5 docs with 8-dim orthogonal embeddings)
   - Build BM25 index for ChromaDB (required -- use `_build_bm25_index_if_needed` pattern from contract tests)
   - Execute hybrid search on both backends with same query + query_embedding
   - For ChromaDB: do vector_search + keyword_search + RRF fusion (same pattern as contract test `_hybrid_search()`)
   - For PostgreSQL: call `hybrid_search_with_rrf()` (PostgresBackend has this built-in method)
   - Extract top-5 chunk_ids from each result set
   - Calculate Jaccard similarity: `len(intersection) / len(union)`
   - Assert `similarity >= 0.6` (60% overlap threshold per research)
   - This validates Success Criteria #2

**Important implementation details:**
- Use `from __future__ import annotations` at top
- All test functions must be `async` (asyncio_mode = "auto" in pyproject.toml handles this)
- Use 8-dimensional embeddings throughout (matching contract test pattern) for speed
- Reset database state in fixture teardown with `await backend.reset()` then `await backend.close()`
- Import `PostgresBackend`, `PostgresConfig` from `agent_brain_server.storage.postgres`
- Import `ChromaBackend` from `agent_brain_server.storage.chroma.backend`
- Import `VectorStoreManager` from `agent_brain_server.storage.vector_store`
- Import `BM25IndexManager` from `agent_brain_server.indexing.bm25_index`
- For the IndexingService test: the IndexingService.index_folder() method requires a DocumentLoader. Create one: `from agent_brain_server.indexing import DocumentLoader; loader = DocumentLoader(); indexing_service = IndexingService(storage_backend=backend, document_loader=loader)`. If index_folder requires an EmbeddingGenerator, mock it to return 8-dim embeddings matching the provider config.
- Actually, since the E2E test with real indexing would require real OpenAI API calls (expensive), use the SIMPLER approach: directly call `await backend.upsert_documents(ids, embeddings, documents, metadatas)` to seed data (matching contract test pattern), then query via the backend. This tests the full PostgreSQL path without requiring API keys.
- For the full workflow test, if you want to test via IndexingService without real API calls, you can mock the EmbeddingGenerator to return 8-dim fake embeddings. But the SIMPLER approach of direct upsert + query is preferred and matches what the research recommends.

**Style requirements:**
- Black-formatted (88 char line length)
- Type hints on all functions (mypy strict)
- Google-style docstrings
- No `Any` type hints where avoidable (use specific types)
- Import sorting per ruff/isort
  </action>
  <verify>
Run from agent-brain-server directory:

```bash
cd /Users/richardhightower/clients/spillwave/src/agent-brain/agent-brain-server
poetry run black tests/integration/test_postgres_e2e.py --check
poetry run ruff check tests/integration/test_postgres_e2e.py
poetry run mypy tests/integration/test_postgres_e2e.py --ignore-missing-imports
```

All three must pass with zero errors.

Then verify test file is properly skipped when DATABASE_URL is not set:
```bash
cd /Users/richardhightower/clients/spillwave/src/agent-brain/agent-brain-server
poetry run pytest tests/integration/test_postgres_e2e.py -v --co 2>&1 | head -20
```

Should show tests collected but marked as skipped (not import errors).
  </verify>
  <done>
`test_postgres_e2e.py` exists with 4 test functions covering all 5 success criteria. File passes black, ruff, and mypy. Tests skip gracefully when DATABASE_URL is not set. No existing test regressions.
  </done>
</task>

<task type="auto">
  <name>Task 2: Verify all existing tests pass and new tests skip gracefully</name>
  <files>agent-brain-server/tests/integration/test_postgres_e2e.py</files>
  <action>
Run `task before-push` from the repository root to verify:
1. All 654+ existing tests still pass
2. New test file is properly collected but skipped (no DATABASE_URL in standard test environment)
3. Code formatting, linting, and type checking all pass
4. No regressions introduced

If `task before-push` fails:
- Fix any Black formatting issues: `cd agent-brain-server && poetry run black tests/integration/test_postgres_e2e.py`
- Fix any Ruff lint issues: `cd agent-brain-server && poetry run ruff check tests/integration/test_postgres_e2e.py --fix`
- Fix any mypy type errors by adjusting type hints in the test file
- Re-run `task before-push` until it passes clean

After `task before-push` passes, also run:
```bash
cd /Users/richardhightower/clients/spillwave/src/agent-brain/agent-brain-server
poetry run pytest tests/integration/test_postgres_e2e.py -v 2>&1 | tail -10
```

Expected: All tests show SKIPPED with reason "PostgreSQL not available" (because DATABASE_URL is not set in local test environment).
  </action>
  <verify>
```bash
cd /Users/richardhightower/clients/spillwave/src/agent-brain
task before-push
```

Must exit with code 0. All tests pass, no lint/type/format errors.

Additionally verify skip behavior:
```bash
cd /Users/richardhightower/clients/spillwave/src/agent-brain/agent-brain-server
poetry run pytest tests/integration/test_postgres_e2e.py -v 2>&1 | grep -E "PASSED|FAILED|SKIPPED|ERROR"
```

Expected output: All tests show SKIPPED (not ERROR).
  </verify>
  <done>
`task before-push` exits 0. All existing tests pass. New E2E test file is collected and gracefully skipped when DATABASE_URL is not set. Zero regressions. Phase 10 is complete and v6.0 milestone is validated.
  </done>
</task>

</tasks>

<verification>
Phase 10 validation:

1. **Success Criteria #1 (E2E with real database):** `test_full_workflow_index_and_query` seeds documents into live PostgreSQL via `upsert_documents()`, queries via `vector_search()`, asserts non-empty results with valid scores. When run with DATABASE_URL pointing to real pgvector database (via Docker Compose or CI service container), this proves the full stack works.

2. **Success Criteria #2 (Cross-backend consistency):** `test_hybrid_search_similarity_chroma_vs_postgres` indexes identical corpus in both backends, runs hybrid search, and asserts 60%+ Jaccard overlap in top-5 results.

3. **Success Criteria #3 (Connection pool under load):** Already validated by existing `tests/load/test_postgres_pool.py::test_connection_pool_under_load` which runs 50 concurrent queries + background indexing against live database. No changes needed.

4. **Success Criteria #4 (/health/postgres metrics):** `test_health_postgres_pool_metrics` validates pool metrics dict contains expected keys and values. The health endpoint at `/health/postgres` (in `routers/health.py`) directly forwards these metrics.

5. **Success Criteria #5 (existing tests pass):** `task before-push` must exit 0 with all 654+ tests passing.

**CI validation:** Tests run automatically in GitHub Actions PR QA Gate because:
- PostgreSQL service container is already configured in `pr-qa-gate.yml`
- `DATABASE_URL` env var is set to `postgresql://postgres:postgres@localhost:5432/agent_brain_test`
- `poetry install --extras postgres` installs asyncpg/sqlalchemy
- All `@pytest.mark.postgres` tests execute in CI

**Local validation:** Developers can run tests locally with:
```bash
docker compose -f agent-brain-server/templates/docker-compose.postgres.yml up -d
export DATABASE_URL="postgresql://agent_brain:agent_brain_dev@localhost:5432/agent_brain"
cd agent-brain-server && poetry run pytest tests/integration/test_postgres_e2e.py -v
docker compose -f agent-brain-server/templates/docker-compose.postgres.yml down
```
</verification>

<success_criteria>
1. `agent-brain-server/tests/integration/test_postgres_e2e.py` exists with 4 test functions
2. Tests skip gracefully when DATABASE_URL is not set (no import errors, no test failures)
3. Tests pass when run against live PostgreSQL (validated in CI via pr-qa-gate.yml)
4. `task before-push` exits 0 with all existing tests passing
5. File passes black (88), ruff, and mypy strict checks
</success_criteria>

<output>
After completion, create `.planning/phases/10-live-postgres-e2e/10-01-SUMMARY.md`
</output>
