---
phase: 01-two-stage-reranking
plan: 07
type: execute
wave: 4
depends_on: ["01-05"]
files_modified:
  - agent-brain-server/README.md
  - docs/USER_GUIDE.md
autonomous: true

must_haves:
  truths:
    - "README documents how to enable reranking"
    - "USER_GUIDE explains two-stage retrieval concept"
    - "Environment variables are documented"
  artifacts:
    - path: "agent-brain-server/README.md"
      provides: "Reranking configuration section"
      contains: "ENABLE_RERANKING"
    - path: "docs/USER_GUIDE.md"
      provides: "Two-stage retrieval explanation"
      contains: "reranking"
  key_links: []
---

<objective>
Update documentation to cover reranking configuration and usage.

Purpose: Enable users to understand and configure two-stage reranking.
Output: Updated README and USER_GUIDE with reranking documentation.
</objective>

<execution_context>
@/Users/richardhightower/.claude/get-shit-done/workflows/execute-plan.md
@/Users/richardhightower/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-two-stage-reranking/01-RESEARCH.md
@.planning/phases/01-two-stage-reranking/01-05-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update server README with reranking section</name>
  <files>agent-brain-server/README.md</files>
  <action>
Read the current README and add a new section for reranking configuration. Add this section after the existing configuration/environment variables section:

```markdown
## Two-Stage Reranking (Feature 123)

Agent Brain supports optional two-stage retrieval with reranking for improved search precision. When enabled, the system:

1. **Stage 1**: Retrieves more candidates than requested (e.g., 50 candidates for top_k=5)
2. **Stage 2**: Reranks candidates using a cross-encoder model for more accurate relevance scoring

### Enabling Reranking

Set the following environment variables:

```bash
# Enable two-stage reranking (default: false)
ENABLE_RERANKING=true

# Choose provider (default: sentence-transformers)
RERANKER_PROVIDER=sentence-transformers  # or "ollama"

# Choose model (default: cross-encoder/ms-marco-MiniLM-L-6-v2)
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# Stage 1 retrieval multiplier (default: 10)
RERANKER_TOP_K_MULTIPLIER=10

# Maximum candidates for Stage 1 (default: 100)
RERANKER_MAX_CANDIDATES=100
```

### Provider Options

| Provider | Model | Latency | Description |
|----------|-------|---------|-------------|
| sentence-transformers | cross-encoder/ms-marco-MiniLM-L-6-v2 | ~50ms | Recommended. Fast, accurate cross-encoder. |
| sentence-transformers | cross-encoder/ms-marco-MiniLM-L-12-v2 | ~100ms | Slower but more accurate. |
| ollama | llama3.2:1b | ~500ms | Fully local, no HuggingFace download. |

### YAML Configuration

You can also configure reranking in `config.yaml`:

```yaml
reranker:
  provider: sentence-transformers
  model: cross-encoder/ms-marco-MiniLM-L-6-v2
  params:
    batch_size: 32
```

### Graceful Degradation

If the reranker fails (model unavailable, timeout, etc.), the system automatically falls back to Stage 1 results. This ensures queries never fail due to reranking issues.

### Response Fields

When reranking is enabled, query results include additional fields:

- `rerank_score`: The cross-encoder relevance score
- `original_rank`: The position before reranking (1-indexed)

Example response:
```json
{
  "results": [
    {
      "text": "Document content...",
      "source": "docs/guide.md",
      "score": 0.95,
      "rerank_score": 0.95,
      "original_rank": 5,
      "chunk_id": "chunk_abc123"
    }
  ]
}
```
```

Place this section after the main configuration section but before advanced topics.
  </action>
  <verify>Read the updated README and confirm the reranking section is present with all environment variables documented.</verify>
  <done>README includes comprehensive reranking documentation.</done>
</task>

<task type="auto">
  <name>Task 2: Update USER_GUIDE with reranking explanation</name>
  <files>docs/USER_GUIDE.md</files>
  <action>
Read the current USER_GUIDE and add a section explaining two-stage reranking. Add this to the query configuration or advanced features section:

```markdown
## Two-Stage Retrieval with Reranking

Agent Brain can optionally use two-stage retrieval to improve search precision by 15-20%.

### How It Works

**Without Reranking (Default)**:
1. Query is embedded using the embedding model
2. Vector similarity search finds top_k most similar documents
3. Results are returned

**With Reranking Enabled**:
1. Query is embedded using the embedding model
2. Vector + BM25 hybrid search retrieves 10x more candidates
3. Cross-encoder model scores each candidate for relevance to the query
4. Results are reordered by cross-encoder score
5. Top_k results are returned

### Why Reranking Helps

Embedding models (bi-encoders) are fast but approximate. They encode the query and documents separately, then compare vectors. This can miss nuanced relevance.

Cross-encoders process the query AND document together, allowing the model to attend across both texts. This is slower but more accurate.

### When to Enable Reranking

Enable reranking when:
- Precision matters more than latency
- Queries are complex or nuanced
- Initial results seem "close but not quite right"

Keep reranking disabled when:
- Latency is critical (real-time search)
- Running on resource-constrained hardware
- Search quality is already acceptable

### Configuration

Enable with environment variable:
```bash
export ENABLE_RERANKING=true
```

Or in config.yaml:
```yaml
reranker:
  provider: sentence-transformers
  model: cross-encoder/ms-marco-MiniLM-L-6-v2
```

### Provider Choices

**sentence-transformers (Recommended)**:
- Uses HuggingFace CrossEncoder models
- Downloads model on first use (~50MB)
- Fast inference (~50ms for 100 candidates)

**ollama (Fully Local)**:
- Uses Ollama chat completions for scoring
- No external downloads
- Slower (~500ms for 100 candidates)
- Requires Ollama running locally
```

Place this section in an appropriate location (after basic query usage, before API reference).
  </action>
  <verify>Read the updated USER_GUIDE and confirm the reranking explanation is present and clear.</verify>
  <done>USER_GUIDE explains two-stage retrieval concept for users.</done>
</task>

</tasks>

<verification>
1. README has complete environment variable documentation
2. README shows YAML config example
3. USER_GUIDE explains the concept in user-friendly terms
4. Both docs mention graceful degradation
5. Provider options are documented with trade-offs
</verification>

<success_criteria>
- Environment variables for reranking are documented
- YAML configuration example is provided
- Concept is explained clearly for non-technical users
- Trade-offs between providers are documented
- Graceful fallback behavior is mentioned
</success_criteria>

<output>
After completion, create `.planning/phases/01-two-stage-reranking/01-07-SUMMARY.md`
</output>
